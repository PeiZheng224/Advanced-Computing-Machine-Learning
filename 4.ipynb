{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80fb662",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "In this lab, we're going to focus on a single classification problem: predicting penguins' sex.\n",
    "\n",
    "## Training a basic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824de872-dd34-4859-8a9b-833280c0b32d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1\n",
    "\n",
    "First, let's choose two numeric features to use for this task. Produce a scatterplot that would be helpful to do this, and choose two numeric features which look like they would be good predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d76ee53",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "penguins_df = sns.load_dataset('penguins') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05e4f092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0    Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1    Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2    Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3    Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4    Adelie  Torgersen            36.7           19.3              193.0   \n",
       "..      ...        ...             ...            ...                ...   \n",
       "339  Gentoo     Biscoe             NaN            NaN                NaN   \n",
       "340  Gentoo     Biscoe            46.8           14.3              215.0   \n",
       "341  Gentoo     Biscoe            50.4           15.7              222.0   \n",
       "342  Gentoo     Biscoe            45.2           14.8              212.0   \n",
       "343  Gentoo     Biscoe            49.9           16.1              213.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "0         3750.0    Male  \n",
       "1         3800.0  Female  \n",
       "2         3250.0  Female  \n",
       "3            NaN     NaN  \n",
       "4         3450.0  Female  \n",
       "..           ...     ...  \n",
       "339          NaN     NaN  \n",
       "340       4850.0  Female  \n",
       "341       5750.0    Male  \n",
       "342       5200.0  Female  \n",
       "343       5400.0    Male  \n",
       "\n",
       "[344 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79379f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74615353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "two_chosen_numeric_features = ['bill_length_mm', 'body_mass_g']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c44003",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Now, let's predict sex using a Logistic Regression model. Fill in the code below to train and evaluate this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa268537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "target_column = 'sex'\n",
    "model_data = penguins_df[two_chosen_numeric_features + [target_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "531d7b40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/49/0rxntbsn5hs0bhv6nxbm70700000gn/T/ipykernel_4946/2013293562.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_data['sex'] = model_data['sex'].apply(lambda x: np.nan if pd.isna(x) else int(x == 'Female'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#  Recode the target column to be 0/1, where 1 indicates that\n",
    "#  the penguin is female\n",
    "#  we could use OneHotEncoder, but let's use pandas instead:\n",
    "model_data['sex'] = model_data['sex'].apply(lambda x: np.nan if pd.isna(x) else int(x == 'Female'))\n",
    "# If we used `model_data['sex'] = model_data['sex'] == 'Female'`, we'd replace the `na` values with False\n",
    "\n",
    "#  There are going to be missing features and missing targets,\n",
    "#  which should be dealt with differently. \n",
    "\n",
    "#  Drop the data which has a missing target variable\n",
    "model_data = model_data[model_data['sex'].notna()]\n",
    "\n",
    "#  We don't want to drop observations with missing features\n",
    "#  Instead, we're going to impute values and add an indicator that the original \n",
    "#  data was missing\n",
    "\n",
    "#  Create variables for each feature which indicate whether any of the features are missing\n",
    "#  Rename them so the columns end in \"_is_na\"\n",
    "na_indicators = model_data[two_chosen_numeric_features].isna().rename(lambda x: x + '_is_na', axis=1)\n",
    "model_data = pd.concat((model_data, na_indicators), axis=1)\n",
    "\n",
    "#  Impute the mean for missing data\n",
    "for col in two_chosen_numeric_features:\n",
    "    model_data[col] = model_data[col].fillna(model_data[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8e00e823",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30     1.0\n",
       "317    1.0\n",
       "79     0.0\n",
       "201    1.0\n",
       "63     0.0\n",
       "      ... \n",
       "288    1.0\n",
       "4      1.0\n",
       "83     0.0\n",
       "319    0.0\n",
       "66     1.0\n",
       "Name: sex, Length: 67, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Split the data test/train\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    model_data[two_chosen_numeric_features], \n",
    "    model_data[target_column], \n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# By default, sklearn's LogisticRegression uses L2 regularization, turn this off by passing penalty=None\n",
    "model = LogisticRegression(penalty=None)\n",
    "model.fit(X_train, y_train)\n",
    "y_train_hat = model.predict(X_train)\n",
    "y_test_hat = model.predict(X_test)\n",
    "\n",
    "y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca11de57",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672b0d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Now we're going to evaluate the performance of this model. Produce the confusion matrices for the test and train predictions, where each cell shows the proportion of the observations in that category. Does the model perform better on the test set or the train set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28689ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Train confusion matrix\")\n",
    "\n",
    "train_cm = confusion_matrix(y_train, y_train_hat)\n",
    "#  confusion_matrix() returns counts, turn into proportions\n",
    "train_cm = ...\n",
    "train_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d1668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(train_cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5c638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Test confusion matrix\")\n",
    "test_cm = confusion_matrix(y_test, y_test_hat)\n",
    "test_cm = ...\n",
    "test_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7afd9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(test_cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4ac82",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Calculate the following metrics: accuracy, false positive and false negative rates, precision and recall, and F1 score (some of these are implemented in `sklearn.metrics`, some you'll have to write yourself based on the confusion matrix).\n",
    "\n",
    "We're going to be looking at these metrics again, so write a function which takes the true and labels as inputs and returns all of these values in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bb74b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def evaluate_predictions(y_true, y_predicted):\n",
    "    ...\n",
    "\n",
    "    return {\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "    }\n",
    "\n",
    "evaluate_predictions(y_test, y_test_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf1abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_predictions(y_train, y_train_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e16c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Produce the ROC plot for this classifier. Does it perform better or worse than chance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfc1090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "\n",
    "#  Get predicted probabilities for both classes for the test set from the model\n",
    "y_proba_test = ...\n",
    "\n",
    "# Predicted probability that the observation is female (a single column)\n",
    "y_proba_female  = ...\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_proba_female,\n",
    "    plot_chance_level=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a7238",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6\n",
    "\n",
    "Produce a calibration table and plot from the model's predictions. In which bucket is the model worst calibrated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250e3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calibration_df = pd.DataFrame({\n",
    "    'true_label': y_test,\n",
    "    'predicted_probability': y_proba_female,\n",
    "})\n",
    "\n",
    "# Use pandas cut method to produce 10 bins\n",
    "calibration_df['predicted_probability_bucket'] = pd.cut(calibration_df['predicted_probability'], bins= ...\n",
    "\n",
    "# The buckets are represented by left and right bounds, calculate the center\n",
    "calibration_df['predicted_probability_bucket_center'] = calibration_df['predicted_probability_bucket'].apply(lambda x: x.left + (x.right - x.left) / 2).astype(float)\n",
    "\n",
    "# Calculate the proportion of positive labels in each bucket\n",
    "# as a DataFrame with two columns, so that it can be plotted by seaborn\n",
    "prop_positive_by_bucket = ...\n",
    "prop_positive_by_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7452e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = sns.lineplot(\n",
    "    data=prop_positive_by_bucket,\n",
    "    x='predicted_probability_bucket_center',\n",
    "    y='true_label',\n",
    ")\n",
    "p.set_title('Calibration plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eab73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_positive_by_bucket['calibration_error'] = ...\n",
    "prop_positive_by_bucket.sort_values('calibration_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e891ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Question 7\n",
    "\n",
    "A \"no-skill\" classifier is often used as a baseline for model performance. It predicts that every observation is in the most common class, with probability equal to the proporition of observations in that class. Produce no-skill predictions and evaluate them using your function from above and the ROC curve.\n",
    "\n",
    "What is the accuracy for the no-skill classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a2dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_observations_female = ...\n",
    "\n",
    "# Predicted probability of label=1 for each observation\n",
    "y_proba_test_no_skill = ...\n",
    "\n",
    "# Prediction for each observation\n",
    "y_hat_test_no_skill = ...\n",
    "\n",
    "evaluate_predictions(y_test, y_hat_test_no_skill)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf210bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_proba_test_no_skill,\n",
    "    plot_chance_level=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd13468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_skill_accuracy = ...\n",
    "no_skill_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d494ff",
   "metadata": {},
   "source": [
    "# Constructing and selecting features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fba4cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "\n",
    "### Question 8\n",
    "\n",
    "We've only used two numeric features so far in our model. Let's prepare the dataset so that we can use all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b8f740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "target_column = 'sex'\n",
    "\n",
    "model_data = penguins_df[~penguins_df[target_column].isna()].reset_index()\n",
    "target = model_data[target_column] == 'Female'\n",
    "\n",
    "#  Using `.dtypes`, select the numeric and categorical feature columns\n",
    "categorical_feature_columns = ...\n",
    "numeric_feature_columns = ...\n",
    "\n",
    "# Remove the target colum from the categorical and numeric feature columns\n",
    "categorical_feature_columns = [c for c in categorical_feature_columns if c != target_column] # SOLUTION\n",
    "numeric_feature_columns = [c for c in numeric_feature_columns if c != target_column] # SOLUTION\n",
    "categorical_feature_columns,  numeric_feature_columns, target_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b981da2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_model_data = model_data[categorical_feature_columns]\n",
    "categorical_na_indicators =  categorical_model_data.isna().rename(lambda x: f'{x}_isna', axis=1)\n",
    "#  Fill in the missing values using the most common value rather than the mean\n",
    "#  (which wouldn't make sense for cateogorical data)\n",
    "categorical_model_data = categorical_model_data.fillna(\n",
    "    ...\n",
    ")\n",
    "\n",
    "\n",
    "# Use a one-hot encoder to encode all the categorical columns\n",
    "enc = OneHotEncoder(drop='first', sparse_output=False) \n",
    "categorical_model_data = ...\n",
    "#  Assign the column names back to the output for readability\n",
    "categorical_model_data = pd.DataFrame(categorical_model_data, columns=enc.get_feature_names_out())\n",
    "\n",
    "categorical_model_data = pd.concat((categorical_model_data, categorical_na_indicators), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3078a38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_model_data = model_data[numeric_feature_columns]\n",
    "\n",
    "numeric_na_indicators =  numeric_model_data.isna().rename(lambda x: f'{x}_isna', axis=1)\n",
    "numeric_model_data = numeric_model_data.fillna(\n",
    "    numeric_model_data.mean()\n",
    ") \n",
    "numeric_model_data = pd.concat((numeric_model_data, numeric_na_indicators), axis=1)\n",
    "\n",
    "\n",
    "# Create the model feature data by concatenating together the numeric and encoded categorical columns\n",
    "model_data = pd.concat((numeric_model_data, categorical_model_data), axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(model_data, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6009b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 9\n",
    "\n",
    "Fit a logistic regression model without regularization and an L1 (LASSO) regularized model to the training data. \n",
    "- Which features are selected, and which are dropped?\n",
    "- Compare the performance of these two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d4ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(penalty=None)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "feature_names = ...\n",
    "logistic_model_coefs = pd.DataFrame({\n",
    "    'name':feature_names, \n",
    "    'coef_logistic':logistic_model.coef_.reshape(-1), \n",
    "})\n",
    "logistic_model_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090646a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regularized_logistic_model = LogisticRegression(penalty='l1', C=0.2, solver='liblinear')\n",
    "regularized_logistic_model.fit(X_train, y_train)\n",
    "feature_names = ...\n",
    "regularized_logistic_model_coefs = pd.DataFrame({\n",
    "    'name':feature_names, \n",
    "    'coef_regularized':regularized_logistic_model.coef_.reshape(-1), \n",
    "})\n",
    "regularized_logistic_model_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da538d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coefs_compared = logistic_model_coefs.merge(regularized_logistic_model_coefs)\n",
    "coefs_compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1d30c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_predictions(y_test, logistic_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd6066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_predictions(y_test, regularized_logistic_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9fcb5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5adf00d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 10\n",
    "\n",
    "\n",
    "Using sklearn's K-fold cross validation, evaluate the preformance of the logistic regression model on the whole dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e450a715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "predictions = []\n",
    "for n_fold, (train_index, test_index) in enumerate(kf.split(model_data)):\n",
    "    # Use the train index and test index to extract the right\n",
    "    #  data for the fold from `model_data` and `target`\n",
    "    X_train = ...\n",
    "    y_train = ...\n",
    "    X_test = ...\n",
    "    y_test = ...\n",
    "\n",
    "    model = LogisticRegression(penalty=None, max_iter=10000)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions.append(pd.DataFrame({\n",
    "        'n_fold': n_fold,\n",
    "        'y_true_test': y_test,\n",
    "        'y_pred_test': model.predict(X_test)\n",
    "    }))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2fc9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.concat(predictions)\n",
    "evaluate_predictions(\n",
    "    predictions_df['y_true_test'],\n",
    "    predictions_df['y_pred_test'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72f5e39",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Additional Questions\n",
    "\n",
    "### Question \n",
    "\n",
    "Calibrate the model's predictions using a second regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bed1fe",
   "metadata": {},
   "source": [
    "### Question \n",
    "\n",
    "Produce predictions which are *worse* than those of the no-skill classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8209b93",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Question \n",
    "\n",
    "Use cross validation to choose the best regularization strength and L1 ratio for an elasticnet-penalized Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af3eefc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60851d98",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b942bb2",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compss211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "lab-5-1",
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
